name: parseq_adapters_128
_target_: strhub.models.parseq.system_adapters.PARSeqWithAdapters

# Data
patch_size: [ 4, 8 ]  # [ height, width ]

# Architecture
embed_dim: 384
enc_num_heads: 6
enc_mlp_ratio: 4
enc_depth: 12
dec_num_heads: 12
dec_mlp_ratio: 4
dec_depth: 1

# Adapter settings
adapter_dim: 128  # LARGER bottleneck dimension (was 64)

# Training
lr: 1e-3  # Higher LR since we're only training adapters
perm_num: 6
perm_forward: true
perm_mirrored: true
dropout: 0.1

# Decoding mode (test)
decode_ar: true
refine_iters: 1

# Charset
charset_train: '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!"#$%&''()*+,-./:;<=>?@[\]^_`{|}~'
charset_test: "0123456789abcdefghijklmnopqrstuvwxyz"
max_label_length: 25
img_size: [ 32, 128 ]
